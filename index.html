<!DOCTYPE HTML>

<html>
	<head>
		<title>Man vs AI</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="assets/css/custom.css">
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

			<!-- Header -->
			<header id="header">
				<a id="logo" class="logo" href="#">Klech</a>
				<nav>
					<ul>
						<li><a href="#home">Home</a></li>
						<li><a href="#intro">Introduction</a></li>
						<li><a href="#questions">Research Questions</a></li>
						<li><a href="#datastory">Datastory</a></li>
						<li><a href="#footer">Team</a></li>
					</ul>
				</nav>
			</header>

			<!-- Home -->
			<section id="home" class="main style1 dark fullscreen" tabindex="">
				<div class="content">
					<header>
						<h2>Man vs AI: A Comparison of Human and LLM Wikispeedia Strategy</h2>
					</header>
					<p id="anim"></p>
				</div>
			</section>

			<!-- Introduction -->
			<section id="intro" class="main style2 right dark fullscreen">
				<div class="content box style2">
					<header>
						<h2>Introduction</h2>
					</header>
					<p>
						LLMs are trained on extremely large corpuses of texts, most of the time written by humans over decades. This enables them to generate human-like sentences and reply to questions in a sound way. But how closely do they adopt human ways of thought? More specifically, can an LLM emulate through behavior the same thinking underpinning human semantic maps? 
					</p> <p>
						To answer this question, we will enlist ChatGPT as a participant in Wikispeedia and evaluate its performance across a subset of popular but meaningfully diverse origin-goal page pairs previously played by humans. 
						Our analysis will first parse ChatGPT's decisions for human 'readability' - that is, we will employ embeddings, TF-IDF vectorization on page content, and Wikispeedia-derived human semantic distances to determine if we, as humans, can justify ChatGPT's chosen paths. 
						We will then will compare ChatGPT's paths to human paths, measuring levels of similarity in rounds-to-goal, 'zoom-in' / 'zoom-out', and rates of 'course correction', thereby quantifying ChatGPT's proximity to human strategization and ex-ante semantic mapping. 
					</p>
				</div>
				<a href="#questions" class="button style2 down anchored">Next</a>
			</section>

			<!-- Research Questions -->
			<section id="questions" class="main style2 left dark fullscreen">
				<div class="content box style2">
					<header>
						<h2>Research Questions</h2>
					</header>
					<ul id="questions-list">
						<li>Does ChatGPT pursue page-paths that are sensical to human researchers?</li>
						<li>Is the previous question's answer robust to different semantic categories?</li>
						<li>How does ChatGPT's rounds-to-goal compare to human players'?</li>
						<li>Does ChatGPT employ the same 'zoom-out' to hub, 'zoom-in' to spoke Wikispeedia strategy as humans?</li>
						<li>How often does ChatGPT 'backtrack' compared to humans?</li>
					</ul>
				</div>
				<a href="#datastory" class="button style2 down anchored">Next</a>
			</section>

			<!-- Datastory -->
			<h2 id="datastory" style="text-align: center; margin-top: 50px">Datastory</h2>
			
			<section class="main style3 primary">
				<div class="content">
					<header>
						<h3>Overview</h3>
						<p>Some words on the total number of games polayed, total finished total unfinished. type of data (graph), goal of wikispeedia. Very few words</p>
					</header>

					<div>
						<div class="flourish-embed flourish-chart" data-src="visualisation/16169106"><script src="https://public.flourish.studio/resources/embed.js"></script></div>
						<p> comments on the plot above <p>

						<div class="flourish-embed flourish-chart" data-src="visualisation/16168925"><script src="https://public.flourish.studio/resources/embed.js"></script></div>
						<p> comments on the plot above <p>
						
						<div class="flourish-embed flourish-sankey" data-src="visualisation/16169537"><script src="https://public.flourish.studio/resources/embed.js"></script></div>
						<p> comments on the plot above <p>
						
						<div class="flourish-embed flourish-sankey" data-src="visualisation/16179089"><script src="https://public.flourish.studio/resources/embed.js"></script></div>
						<p> comments on the plot above <p>
						
						<p> Final words on this section, introduction to the next. </p>
					</div>

				</div>
			</section>

			<section class="gray main style3">
				<div class="content">
					<header>
						<h3>Choice of LLM</h3>						
					</header>
					
					<div>
						<p>Since our project involves letting the 'AI' play the Wikispeedia game, we need to find an LLM that is able to play by following the commands.
						The best and first choice would have been <span class="bold">ChatGPT</span> with the <span class="italic">OpenAI - API</span>. However, our choice is restricted by resources (both computational
						and economical). Hence, we rescricted the scope of our research to the models with less than 13B parameters publicly available on the <span class="italic">HuggingFace</span> repository.
						After looking at the HF leaderboard, we focused on the following two models:
							
						<ol>
							<li><span class="bold">LlaMA-13B</span> (see the model on <a href="https://huggingface.co/meta-llama/Llama-2-13b-hf">hugging-face</a>)</li>
							<li><span class="bold">Mistral-7B</span> (see the model on <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">hugging-face</a>)</li>
						</ol>
							
						Note that: for all these models, we selected the <span class="italic">instruct</span> version, which means that the model is trained to follow instructions.
							
						While LlaMA-13B has more parameters than Mistral-7B, it was not performing as good (as the <a href="https://arxiv.org/pdf/2310.06825.pdf">results</a> from Jiang, Albert Q., et al. are also proving):
						</p>
						
						<img src="./assets/images/analysis_imgs/MISTRALvsLLaMA_hist.png" alt="Mistral vs LLaMA hist" width="100%" height=auto>
						<img src="./assets/images/analysis_imgs/MISTRALvsLLaMA_table.png" alt="Mistral vs LLaMA table" width="100%" height=auto>
						<p>Final words on this section, introduction to the next. </p>
					<div>
				</div>
			</section>

			<section class="main style3 primary">
				<div class="content">
					<header>
						<h3>Human vs Mistral: Who is better at Wikispeedia?</h3>
						<p>Our first route of investigation stems from the rather natural and universal question of whether AI can outperform humans in tasks requiring critical thought. To answer this in the realm of Wikispeedia, we first process Mistral’s prompt responses so they conform to the structure of preexisting, human-derived Wikispeedia data. We then (1) drop all games where the human player quit or the Mistral game was aborted due to our 20-page maximum permittance (which we established to reduce computation time) and (2) calculate average human game length and average Mistral game length for each game pair. These averages are plotted below alongside 95% confidence intervals; those game pair labels rendered bold exhibit a statistically significant difference in average game length between humans and Mistral. Finally, note that game pairs are sorted by the difference in average game length, meaning the higher the game pair is in the chart, the more the average human outperforms Mistral..</p>
					</header>

					<div>
						<img src="./assets/images/analysis_imgs/human_vs_mistral_kaede.png" alt="Human vs Mistral">
						<p>Those who spend unpaid manhours clicking through Wikipedia links for fun need not worry: the balance of game length – or speed - appears to be in humans’ favor. Across the 75 game pairs we had Mistral play (but not necessarily finish) 30 times each, just 5 show Mistral beating humans’ average speed with statistical significance. Humans, meanwhile, trump Mistral in 29 game pairs – nearly 40% of the set. What’s more, the scale of humanity’s wins is often larger than Mistral’s, as humanity can claim the top 19 highest-magnitude speed differentials. This is all to say that if you select a random game pair, humans are more likely than Mistral to be speedier at it, and when humans win, they win big..</p>
						<p>We formalize our finding that humans are generally the speedier Wikispeedia player on a global scale through a t-test on game length across matched observations. If HF<sub>i</sub> is the number of finished human game paths for game pair i, and MF<sub>i</sub> is the number of finished Mistral game paths for game pair i, we sample min(HF<sub>i</sub>,MF<sub>i</sub>) observations from both human and Mistral data for each game pair i, match human observations to Mistral observations using game pair, take the difference in each pair’s game length, and perform a t-test for difference from 0 on the global set of these differences. We find humans use approximately one page less to reach their target in the matched set (this result is significant at the 99% confidence level). </p>
						<p>EXACT RESULT IN CASE WE WANT A GRAPHIC OR CARD: t-statistic: -8.777983246249146, p-value: 3.8352417389369964e-18, avg: -0.9988726042841037</p>

						<p>We should note that speed is not the only metric for measuring performance. Completion rate is an important metric as well. After all, what good is a talented athlete if he or she quits halfway through every game? Below, we report the cumulative proportion of games completed over time by both Mistral and humans in the top 5 most-played games without a clear speed-based winner. Above, these games were a wash. Notice now how completion rates paint a different picture:</p>
						<img src="./assets/images/analysis_imgs/cumulative_completed.png" alt="Cumulative Completed">
						<p>Clearly, Mistral has greater follow through in these game pairs than humans do. Perhaps drawn toward certain game pairs by perceived ease (Brain -> Telephone) or interesting pages (Cat->Computer, because who doesn’t love cats?) only to realize the game pair is more cumbersome than initially believed, humans appear prone to abandon attempts. Mistral, meanwhile, doesn’t have this freedom under our current prompt; it can only ‘abandon’ a game when it has made too many traversals or engaged in too many cycles. That it isn’t forced to abandon more games under these conditions suggests it is perceived difficulty rather than actual difficulty (which would take the form of exclusively non-semantically-intuitive paths toward the goal) that encourages humans to quit. Mistral is immune to the demoralizing effect of this perception, and is stronger player for it.
							Yet the reason behind differences in completion rates is immediately intuitive. Less so the reason behind differences in speed. We thus turn our focus toward understanding <em>why</em> humans tend to be faster than Mistral among completed game paths. 
							</p>
					</div>
				</div>
			</section>

			<section class="gray main style3">
				<div class="content">
					<header>
						<h3>Why?</h3>
						<p>introduction to investigation methods:
							- heatmaps
							- zoom out zoom in 
							- semantic distance step to step + step to goal 
							- how sensical to human (overlap between paths)
						</p>
					</header>

					<div>
						<img src="./assets/images/analysis_imgs/heatmap_human.png" width="100%" alt="Heatmap human">
						<img src="./assets/images/analysis_imgs/heatmap_mistral.png" width="100%" alt="Heatmap mistral">
						<p>Comments on the plot above (NOTE: should be put image side by side and smaller. Also all the other plots should be smaller) </p>
					</div>
				</div>
			</section>

			<section class="main style3 primary">
				<div class="content">
					<header>
						<h3>Conclusions</h3>
						<p>Put a nice meme. Write some conclusions</p>
					</header>

				</div>
			</section>

			<!-- Footer -->
			<footer id="footer">
					<section id="contact-section" class="features contact"> 
						<div class="contact-container"> 
							<div class="row m-b-10" style="margin-bottom: 4%;">
								<div class="col-lg-12 text-center">
									 <div class="navy-line"></div> 
									 <h1 style="font-size: 150%;">Team</h1>
							</div>
							</div>
							<div class="row justify-content-center">
								<div class="col-sm-2">
									<div class="team-member">
										<h4><span class="navy">Ernesto</span> Bocini</h4>
										<p>______</p>
										<ul class="list-inline social-icon"> 
											<li><a href="https://github.com/ernestoBocini" target="blank"><i class="icon brands fa-github"></i></a> </li>
											<li><a href="mailto:ernesto.bocini@epfl.ch"><i class="fa fa-envelope"></i></a></li>
										</ul>
									</div>
								</div>
								<div class="col-sm-2">
									<div class="team-member">
										<h4><span class="navy">Lorenzo</span> Drudi</h4>
										<p>______</p>
										<ul class="list-inline social-icon">
											<li><a href="https://github.com/drudilorenzo" target="blank"><i class="icon brands fa-github"></i></a> </li>
											<li><a href="mailto:lorenzo.drudi@epfl.ch"><i class="fa fa-envelope"></i></a></li>
										</ul>
									</div>
								</div>
								<div class="col-sm-2">
									<div class="team-member">
										<h4><span class="navy">Kaede</span> Johnson</h4>
										<p>______</p>
										<ul class="list-inline social-icon">
											<li><a href="https://github.com/kaedejohnson" target="blank"><i class="icon brands fa-github"></i></a> </li>
											<li><a href="mailto:kaede.johnson@epfl.ch"><i class="fa fa-envelope"></i></a> </li>
										 </ul>
									</div>
								</div>
								<div class="col-sm-2">
									<div class="team-member">
										<h4><span class="navy">Hanwen</span> Zhang</h4>
										<p>______</p>
										<ul class="list-inline social-icon">
											<li><a href="https://github.com/Katie-zhang" target="blank"><i class="icon brands fa-github"></i></a> </li>
											<li><a href="mailto:hanwen.zhang@epfl.ch"><i class="fa fa-envelope"></i></a> </li>
										</ul>
									</div>
								</div>
								<div class="col-sm-2">
									<div class="team-member">
										<h4><span class="navy">Xingyue</span> Zhang</h4>
										<p>______</p>
										<ul class="list-inline social-icon">
											<li><a href="https://github.com/bREAKtHEdOLL" target="blank"><i class="icon brands fa-github"></i></a> </li>
											<li><a href="mailto:Xingyue.zhang@epfl.ch"><i class="fa fa-envelope"></i></a> </li>
										</ul>
									</div>
								</div>
							</div>

					<ul id="repo-link" class="menu">
						<li><a href="https://github.com/epfl-ada/ada-2023-project-klech" class="icon brands fa-github"><span class="label">Github</span></a></li>
						<li >&copy; KlechxADA</li></li>
					</ul>

			</footer>

			<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="assets/js/typing.js"></script>

			<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
			<script src="https://cdn.jsdelivr.net/npm/popper.js@1.12.9/dist/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
			<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
	</body>
</html>